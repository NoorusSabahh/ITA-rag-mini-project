# ITA-rag-mini-project

This project uses Retrieval-Augmented Generation (RAG) to build a Question Answering system on women legal documents in Pakistan. It includes scraping, parsing PDFs using LlamaParse, converting content to markdowns, indexing, and querying using LLMs.

## ğŸ“ Project Structure

```bash
â”œâ”€â”€ women_laws_pdfs/ # Raw PDFs scraped or uploaded manually
â”œâ”€â”€ markdowns/ # Parsed markdowns generated from PDFs
â”œâ”€â”€ pdf-to-md-parser.py # PDF to Markdown parser using LlamaParse
â”œâ”€â”€ ita-rag.ipynb # the notebook for this project
â”œâ”€â”€ pk-women-law-scraper.py # Scraper for pro-women laws from NCSW and other sources
â”œâ”€â”€ README.md # Project guide (you're here!)
```

## âš™ï¸ Setup Instructions
ğŸ§¬ 1. Clone the Repository
```bash
git clone https://github.com/NoorusSabahh/ITA-rag-mini-project.git
cd ITA-rag-mini-project
```
ğŸ” 2. Set Up API Keys

Groq API: Visit Groq's website and get your API key.

LlamaParse API: Visit Llama Cloud and get your API key.
```bash
import os

os.environ["GROQ_API_KEY"] = "your_groq_api_key"
os.environ["LLAMA_CLOUD_API_KEY"] = "your_llama_key"

GROQ_URL = "https://api.groq.com/openai/v1/chat/completions"
```

âš¡ 3. Enable GPU (if not using Groq)

If you're not using Groq for inference:

- Go to Settings â†’ Accelerator â†’ GPU

- Save and restart the runtime

ğŸ“¦ 4. Install Required Packages

```bash
!pip install langchain pypdf chromadb sentence-transformers langchain_community rank_bm25 faiss-cpu
!pip install -U langchain-huggingface
!pip install pymupdf
```

ğŸ“„ 5. Upload and Load Markdown Files

If you're not converting from PDF, upload your prepared markdowns folder to Kaggleâ€™s input section, then read it like this:
```bash
import os
from langchain_core.documents import Document

markdown_folder = "/kaggle/input/markdowns"
all_docs = []

for md_file in os.listdir(markdown_folder):
    if md_file.endswith(".md"):
        md_path = os.path.join(markdown_folder, md_file)

        with open(md_path, "r", encoding="utf-8") as file:
            content = file.read()

        metadata = {"source": md_file}
        all_docs.append(Document(page_content=content, metadata=metadata))
```

ğŸ› ï¸ 6. (Optional) Parse PDFs using LlamaParse

- Install Required Packages

```bash
pip install llama-cloud-services llama-index-core llama-index-readers-file
```
- Set API Keys
  ```bash
  import os
  os.environ["LLAMA_CLOUD_API_KEY"] = "your_llama_parse_key"
  ```
 - Place your PDFs in the women_laws_pdfs/ directory.
- Run the following to parse PDFs into markdowns:

```bash
python parser.py
```
  - The script will save markdowns in the markdowns/ folder.

â–¶ï¸ 7. Run the RAG Pipeline
Once your documents are loaded:

Run the entire notebook


## ğŸ§  Experimental Options
- Try different chunk sizes and overlaps

- Compare MMR vs. similarity search

- Test various embedding models (HuggingFace, Groq API)

- Use rerankers (e.g., CrossEncoder)

- Summarize long retrieved docs for dense prompts

âœ¨ Credits
This project was built as part of Introduction to Text Analytics Course Mini Project at IBA Karachi, focused on applying RAG pipelines to Pakistani legal datasets â€” particularly laws impacting womenâ€™s rights.
