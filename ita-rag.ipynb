{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11391525,"sourceType":"datasetVersion","datasetId":7132766},{"sourceId":11475050,"sourceType":"datasetVersion","datasetId":7191745},{"sourceId":11485785,"sourceType":"datasetVersion","datasetId":7199015}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"8bc92db0a26846f1a36d22ff41044083":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6425c5fb5da64785b74380ee0def978a","IPY_MODEL_f9d995c251634ba0bbcff1ba58feb1a1","IPY_MODEL_ff8aebc1036f43168d9265ec2c57aa0b"],"layout":"IPY_MODEL_0fc88e3698814e82bfce61708776745e"}},"6425c5fb5da64785b74380ee0def978a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8a93958312a4e57bb30794fbd7d20d8","placeholder":"​","style":"IPY_MODEL_fc371990bf004805839f7d330152cd93","value":"Loading checkpoint shards: 100%"}},"f9d995c251634ba0bbcff1ba58feb1a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c8d6df5014f4d56881a6790503dda60","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_90f21a11cb2848ccb478c4ad9cfba1e4","value":4}},"ff8aebc1036f43168d9265ec2c57aa0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a48b10dd2e24542bb4361a78cad688a","placeholder":"​","style":"IPY_MODEL_5fe61560335546cb9cbbc3aef56c8dc3","value":" 4/4 [01:04&lt;00:00, 19.90s/it]"}},"0fc88e3698814e82bfce61708776745e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8a93958312a4e57bb30794fbd7d20d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc371990bf004805839f7d330152cd93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c8d6df5014f4d56881a6790503dda60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90f21a11cb2848ccb478c4ad9cfba1e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a48b10dd2e24542bb4361a78cad688a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fe61560335546cb9cbbc3aef56c8dc3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Only install faiss-cpu (skip faiss-gpu)\n!pip install langchain pypdf chromadb sentence-transformers langchain_community rank_bm25 faiss-cpu\n!pip install -U langchain-huggingface\n!pip install pymupdf\n\n# Now import\nfrom langchain_community.document_loaders import PyPDFLoader\nfrom langchain.schema import Document\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import FAISS\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom rank_bm25 import BM25Okapi\nimport numpy as np\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\nimport textwrap\nfrom IPython.display import Markdown, display\n\nfrom langchain_huggingface import HuggingFaceEmbeddings\nfrom langchain.vectorstores import FAISS\nimport fitz  # PyMuPDF\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nimport textwrap\nfrom sklearn.metrics.pairwise import cosine_similarity\n","metadata":{"trusted":true,"id":"nNi6x4EwnWo0","outputId":"3aa6a53b-8c5c-4b4b-cd01-7ee425232dae","execution":{"iopub.status.busy":"2025-04-20T11:21:36.782104Z","iopub.execute_input":"2025-04-20T11:21:36.782467Z","iopub.status.idle":"2025-04-20T11:24:27.125921Z","shell.execute_reply.started":"2025-04-20T11:21:36.782445Z","shell.execute_reply":"2025-04-20T11:24:27.124100Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\nRequirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.4.0)\nCollecting chromadb\n  Downloading chromadb-1.0.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\nCollecting langchain_community\n  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\nCollecting rank_bm25\n  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.35)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\nRequirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.16)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\nRequirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\nCollecting build>=1.0.3 (from chromadb)\n  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\nCollecting chroma-hnswlib==0.7.6 (from chromadb)\n  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\nCollecting fastapi==0.115.9 (from chromadb)\n  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\nCollecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\nCollecting posthog>=2.4.0 (from chromadb)\n  Downloading posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.1)\nCollecting onnxruntime>=1.14.1 (from chromadb)\n  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\nRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\nCollecting pypika>=0.48.9 (from chromadb)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\nRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\nRequirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\nCollecting bcrypt>=4.0.1 (from chromadb)\n  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\nCollecting kubernetes>=28.1.0 (from chromadb)\n  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\nCollecting mmh3>=4.0.1 (from chromadb)\n  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\nRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\nRequirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (14.0.0)\nRequirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\nCollecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\nCollecting langchain-core<1.0.0,>=0.3.34 (from langchain)\n  Downloading langchain_core-0.3.54-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain\n  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nCollecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.19.0)\nCollecting pyproject_hooks (from build>=1.0.3->chromadb)\n  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.22.3)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\nRequirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\nRequirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\nRequirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\nCollecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.26.4->langchain) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.26.4->langchain) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.26.4->langchain) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.26.4->langchain) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.26.4->langchain) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.26.4->langchain) (2.4.1)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\nRequirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (75.1.0)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.67.0)\nCollecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\nCollecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb)\n  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\nCollecting protobuf (from onnxruntime>=1.14.1->chromadb)\n  Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nCollecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\nCollecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\nCollecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\nCollecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\nCollecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\nCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1.26.4->langchain) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1.26.4->langchain) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.26.4->langchain) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2,>=1.26.4->langchain) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2,>=1.26.4->langchain) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\nDownloading chromadb-1.0.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\nDownloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\nDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.54-py3-none-any.whl (433 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\nDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\nDownloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\nDownloading opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl (12 kB)\nDownloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl (30 kB)\nDownloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl (16 kB)\nDownloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_util_http-0.53b1-py3-none-any.whl (7.3 kB)\nDownloading opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading durationpy-0.9-py3-none-any.whl (3.5 kB)\nDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nDownloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\nDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53801 sha256=0be707ca6616eb14f052110a31399b363bb718d0cec64ce78168d23b524b6311\n  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\nSuccessfully built pypika\nInstalling collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, python-dotenv, pyproject_hooks, protobuf, opentelemetry-util-http, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, mmh3, humanfriendly, httpx-sse, httptools, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, build, pydantic-settings, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, nvidia-cusolver-cu12, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, langchain-core, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, opentelemetry-instrumentation-fastapi, langchain, onnxruntime, chroma-hnswlib, rank_bm25, langchain_community, faiss-cpu, chromadb\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: opentelemetry-api\n    Found existing installation: opentelemetry-api 1.16.0\n    Uninstalling opentelemetry-api-1.16.0:\n      Successfully uninstalled opentelemetry-api-1.16.0\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: opentelemetry-semantic-conventions\n    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n  Attempting uninstall: opentelemetry-sdk\n    Found existing installation: opentelemetry-sdk 1.16.0\n    Uninstalling opentelemetry-sdk-1.16.0:\n      Successfully uninstalled opentelemetry-sdk-1.16.0\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.35\n    Uninstalling langchain-core-0.3.35:\n      Successfully uninstalled langchain-core-0.3.35\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.6\n    Uninstalling langchain-text-splitters-0.3.6:\n      Successfully uninstalled langchain-text-splitters-0.3.6\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.18\n    Uninstalling langchain-0.3.18:\n      Successfully uninstalled langchain-0.3.18\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\ngoogle-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-1.0.5 coloredlogs-15.0.1 durationpy-0.9 faiss-cpu-1.10.0 fastapi-0.115.9 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 kubernetes-32.0.1 langchain-0.3.23 langchain-core-0.3.54 langchain-text-splitters-0.3.8 langchain_community-0.3.21 mmh3-5.1.0 monotonic-1.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.21.1 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-instrumentation-0.53b1 opentelemetry-instrumentation-asgi-0.53b1 opentelemetry-instrumentation-fastapi-0.53b1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 opentelemetry-util-http-0.53b1 posthog-3.25.0 protobuf-5.29.4 pydantic-settings-2.9.1 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.0 rank_bm25-0.2.2 starlette-0.45.3 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5\nCollecting langchain-huggingface\n  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.30.2)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.3.54)\nRequirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (3.4.1)\nRequirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.0)\nRequirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.51.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2025.3.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.13.1)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.3.8)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (9.0.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.11.3)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.5.1+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.15.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.1.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.2)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers>=4.39.0->langchain-huggingface) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers>=4.39.0->langchain-huggingface) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers>=4.39.0->langchain-huggingface) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers>=4.39.0->langchain-huggingface) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers>=4.39.0->langchain-huggingface) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers>=4.39.0->langchain-huggingface) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.6.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers>=4.39.0->langchain-huggingface) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers>=4.39.0->langchain-huggingface) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers>=4.39.0->langchain-huggingface) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers>=4.39.0->langchain-huggingface) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers>=4.39.0->langchain-huggingface) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.1)\nDownloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\nInstalling collected packages: langchain-huggingface\nSuccessfully installed langchain-huggingface-0.1.2\nCollecting pymupdf\n  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\nDownloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pymupdf\nSuccessfully installed pymupdf-1.25.5\n","output_type":"stream"},{"name":"stderr","text":"2025-04-20 11:24:12.353826: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745148252.574168      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745148252.636768      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/1060099464.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMarkdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_huggingface\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHuggingFaceEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfitz\u001b[0m  \u001b[0;31m# PyMuPDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_huggingface/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from langchain_huggingface.chat_models import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mChatHuggingFace\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[import-not-found]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m from langchain_huggingface.embeddings import (\n\u001b[1;32m      5\u001b[0m     \u001b[0mHuggingFaceEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_huggingface/chat_models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from langchain_huggingface.chat_models.huggingface import (  # type: ignore[import-not-found]\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mTGI_MESSAGE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mTGI_RESPONSE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mChatHuggingFace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0m_convert_message_to_chat_message\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_huggingface/chat_models/huggingface.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLLMResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunnables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseTool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_calling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_to_openai_tool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_validator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/tools/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mmodule_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dynamic_imports\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__spec__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_import_utils.py\u001b[0m in \u001b[0;36mimport_attr\u001b[0;34m(attr_name, module_name, package)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{module_name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"module '{package!r}.{module_name!r}' not found\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mrun_in_executor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m )\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunnables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunnables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoro_with_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m from langchain_core.utils.function_calling import (\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'set_config_context' from 'langchain_core.runnables.config' (/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/config.py)"],"ename":"ImportError","evalue":"cannot import name 'set_config_context' from 'langchain_core.runnables.config' (/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/config.py)","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"!pip install torch\nimport torch  # Import the torch module","metadata":{"id":"Ea2Swe3i9MD8","outputId":"c7d265dd-1a9d-40b1-cee2-0dc73bea287f"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Uncomment the cells below if you're not using Groq API","metadata":{}},{"cell_type":"code","source":"# model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n\n# model = AutoModelForCausalLM.from_pretrained(\n#     model_name,\n#     device_map=\"auto\",\n#     torch_dtype=torch.bfloat16,\n#     trust_remote_code=True,\n# )\n# tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# print(f\"Model dtype: {model.dtype}\")\n# total_params = sum(p.numel() for p in model.parameters())\n# print(f\"Total Parameters: {total_params / 1e6} million\")\n\n# generator = pipeline(\n#     \"text-generation\",\n#     model=model,\n#     tokenizer=tokenizer,\n#     return_full_text=False,\n#     max_new_tokens=1000,\n#     do_sample=True,\n#     temperature=0.8,\n#     top_p=0.9\n# )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T07:09:44.407963Z","iopub.execute_input":"2025-04-15T07:09:44.408233Z","iopub.status.idle":"2025-04-15T07:09:54.017266Z","shell.execute_reply.started":"2025-04-15T07:09:44.408212Z","shell.execute_reply":"2025-04-15T07:09:54.014222Z"},"id":"kHp3HcFYnWo2","outputId":"24c78aca-42af-4ac2-c628-93e51b18f24c"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom langchain.schema import Document\n\nmarkdown_folder = '/kaggle/input/markdowns'  # Path to the folder with markdown files\nall_docs = []\n\nfor md_file in os.listdir(markdown_folder):\n    if md_file.endswith('.md'):\n        md_path = os.path.join(markdown_folder, md_file)\n\n        with open(md_path, 'r', encoding='utf-8') as file:\n            content = file.read()\n\n        metadata = {\n            \"source\": md_file\n        }\n\n        all_docs.append(Document(page_content=content, metadata=metadata))\n\nprint(f\"Total markdown files loaded: {len(all_docs)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:20:23.600403Z","iopub.execute_input":"2025-04-20T11:20:23.601429Z","iopub.status.idle":"2025-04-20T11:20:23.821903Z","shell.execute_reply.started":"2025-04-20T11:20:23.601398Z","shell.execute_reply":"2025-04-20T11:20:23.821126Z"},"id":"cJb6gLOBnWo3","outputId":"bc95fbab-60a8-4cc8-ccea-82cf04cb0c07"},"outputs":[{"name":"stdout","text":"Total markdown files loaded: 61\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"Uncomment the cell below if you're loading PDFs and parsing them on the go. (Not recommended)","metadata":{}},{"cell_type":"code","source":"# import os\n# import fitz  # PyMuPDF\n# from langchain.schema import Document\n\n# pdf_folder = '/kaggle/input/women-laws-pak'  # Path to the folder\n# all_pages = []\n\n# for pdf_file in os.listdir(pdf_folder):\n#     if pdf_file.endswith('.pdf'):\n#         pdf_path = os.path.join(pdf_folder, pdf_file)\n\n#         doc = fitz.open(pdf_path)\n#         for page in doc:\n#             text = page.get_text(\"text\")\n#             metadata = {\n#                 \"source\": pdf_file,\n#                 \"page\": page.number,\n#                 \"total_pages\": len(doc)\n#             }\n#             all_pages.append(Document(page_content=text, metadata=metadata))\n\n#         doc.close()\n\n# print(f\"Total pages loaded: {len(all_pages)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:26:14.030658Z","iopub.execute_input":"2025-04-20T11:26:14.031097Z","iopub.status.idle":"2025-04-20T11:26:18.428675Z","shell.execute_reply.started":"2025-04-20T11:26:14.031061Z","shell.execute_reply":"2025-04-20T11:26:18.427631Z"}},"outputs":[{"name":"stdout","text":"Total pages loaded: 714\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from langchain.text_splitter import TokenTextSplitter\nfrom langchain.text_splitter import SentenceTransformersTokenTextSplitter","metadata":{"id":"-X0f9c46hbV0"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# text_splitter = RecursiveCharacterTextSplitter(\n#     chunk_size=1024,\n#     chunk_overlap=64, \n#     separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n# )\n\n\n# text_splitter = SentenceTransformersTokenTextSplitter(\n#     chunk_size=1024,\n#     chunk_overlap=64,\n#     model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n# )\n\n# chunks = text_splitter.split_documents(all_pages)\n\n# texts = [chunk.page_content for chunk in chunks]\n# metadata = [chunk.metadata for chunk in chunks]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T07:09:54.023445Z","iopub.status.idle":"2025-04-15T07:09:54.024052Z","shell.execute_reply.started":"2025-04-15T07:09:54.023850Z","shell.execute_reply":"2025-04-15T07:09:54.023870Z"},"id":"1UasU94MnWo3"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # from langchain.text_splitter import CharacterTextSplitter\n\n# # text_splitter = CharacterTextSplitter(\n# #     separator=\"\\n\",  # or just \" \" if needed\n# #     chunk_size=256,\n# #     chunk_overlap=30\n# # )\n# # chunks = text_splitter.split_documents(all_pages)\n\n# import nltk\n\n# # Now force clean download\n# nltk.download('punkt_tab')\n\n# from langchain.text_splitter import NLTKTextSplitter\n\n# # Create the NLTK-based splitter\n# text_splitter = NLTKTextSplitter(\n#     chunk_size=1345,\n#     chunk_overlap=42\n# )\n\n# # Split your documents (all_pages must be a list of Document objects)\n# chunks = text_splitter.split_documents(all_pages)\n\n# from langchain.text_splitter import TokenTextSplitter\n\n# # Create the TokenTextSplitter\n# text_splitter = TokenTextSplitter(\n#     chunk_size=2048,       # Number of tokens per chunk\n#     chunk_overlap=200       # Overlap in tokens between chunks\n# )\n\n# # Split your documents (all_pages must be a list of Document objects)\n# chunks = text_splitter.split_documents(all_pages)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from langchain.embeddings import HuggingFaceEmbeddings\n\n# embedding_model = HuggingFaceEmbeddings(\n#     model_name=\"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\",\n#     encode_kwargs={\"normalize_embeddings\": True}\n# )\n\n\n# vectordb = FAISS.from_texts(texts, embedding_model, metadatas=metadata)\n# vectordb.save_local(\"women_laws_faiss_index\")\n\n# num_embeddings = len(vectordb.index.reconstruct_n(0, vectordb.index.ntotal))\n# print(f\"Number of embeddings in vector store: {num_embeddings}\")\n# print(f\"Number of text chunks processed: {len(texts)}\")\n\n# assert num_embeddings == len(texts), \"Mismatch between embeddings and text chunks\"\n\n# tokenized_texts = [text.split() for text in texts]\n# bm25 = BM25Okapi(tokenized_texts)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T07:09:54.030750Z","iopub.status.idle":"2025-04-15T07:09:54.031127Z","shell.execute_reply.started":"2025-04-15T07:09:54.030956Z","shell.execute_reply":"2025-04-15T07:09:54.030973Z"},"id":"yjRmoXtjnWo3"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from langchain.embeddings import HuggingFaceEmbeddings\n\n# Function for chunking and splitting documents\ndef chunk_and_split(all_docs, chunk_size, overlap=64):\n    global embedding_model, vectordb, texts, metadata, bm25\n    text_splitter = SentenceTransformersTokenTextSplitter(\n        chunk_size=chunk_size,\n        chunk_overlap=overlap,\n        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n    )\n    \n    chunks = text_splitter.split_documents(all_docs)\n    \n    texts = [chunk.page_content for chunk in chunks]\n    metadata = [chunk.metadata for chunk in chunks]\n    \n    embedding_model = HuggingFaceEmbeddings(\n        model_name=\"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\",\n        encode_kwargs={\"normalize_embeddings\": True}\n    )\n    \n    vectordb = FAISS.from_texts(texts, embedding_model, metadatas=metadata)\n    vectordb.save_local(f\"women_laws_faiss_index_{chunk_size}\")\n    \n    num_embeddings = len(vectordb.index.reconstruct_n(0, vectordb.index.ntotal))\n    print(f\"Number of embeddings in vector store for chunk size {chunk_size}: {num_embeddings}\")\n    print(f\"Number of text chunks processed for chunk size {chunk_size}: {len(texts)}\")\n    \n    assert num_embeddings == len(texts), f\"Mismatch between embeddings and text chunks for chunk size {chunk_size}\"\n    \n    tokenized_texts = [text.split() for text in texts]\n    bm25 = BM25Okapi(tokenized_texts)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T07:09:54.032433Z","iopub.status.idle":"2025-04-15T07:09:54.032789Z","shell.execute_reply.started":"2025-04-15T07:09:54.032617Z","shell.execute_reply":"2025-04-15T07:09:54.032631Z"},"id":"ubZNZBSenWo4","outputId":"e658bee7-ab96-415a-a1c0-4109604ff3bd"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def linear_score_fusion(results_bm25, results_embedding, alpha=0.5):\n    scores = {}\n    for doc, score in results_bm25:\n        doc_id = doc.page_content\n        scores[doc_id] = scores.get(doc_id, 0) + alpha * score\n\n    for doc, score in results_embedding:\n        doc_id = doc.page_content\n        scores[doc_id] = scores.get(doc_id, 0) + (1 - alpha) * score\n\n    return sorted(scores.items(), key=lambda x: x[1], reverse=True)\n\ndef reciprocal_rank_fusion(results_bm25, results_embedding):\n    scores = {}\n\n    for rank, (doc, score) in enumerate(results_bm25):\n        doc_id = doc.page_content\n        scores[doc_id] = scores.get(doc_id, 0) + 1 / (rank + 1)\n\n    for rank, (doc, score) in enumerate(results_embedding):\n        doc_id = doc.page_content\n        scores[doc_id] = scores.get(doc_id, 0) + 1 / (rank + 1)\n\n    return sorted(scores.items(), key=lambda x: x[1], reverse=True)\n\ndef mmr_rerank(query_embedding, doc_embeddings, docs, lambda_param=0.5, k=5):\n    selected = []\n    selected_indices = []\n    doc_indices = list(range(len(docs)))\n    doc_embeddings = np.array(doc_embeddings)\n    query_embedding = np.array(query_embedding).reshape(1, -1)\n\n    similarity_to_query = cosine_similarity(doc_embeddings, query_embedding).flatten()\n    similarity_between_docs = cosine_similarity(doc_embeddings)\n\n    for _ in range(k):\n        mmr_scores = []\n        for idx in doc_indices:\n            if idx in selected_indices:\n                continue\n            if not selected:\n                diversity_penalty = 0\n            else:\n                diversity_penalty = max(similarity_between_docs[idx][j] for j in selected_indices)\n            mmr_score = lambda_param * similarity_to_query[idx] - (1 - lambda_param) * diversity_penalty\n            mmr_scores.append((idx, mmr_score))\n\n        selected_idx = max(mmr_scores, key=lambda x: x[1])[0]\n        selected.append(docs[selected_idx])\n        selected_indices.append(selected_idx)\n\n    return selected\n\ndef retrieve(query, k, summarize=True, lambda_param=0.5):\n    # Dense retrieval: Get top-k similar docs + their embeddings\n    query_embedding = embedding_model.embed_query(query)\n    results_embedding = vectordb.similarity_search_with_score(query, k=24)  # larger k for reranking\n\n    dense_docs = [doc for doc, _ in results_embedding]\n    dense_embeddings = embedding_model.embed_documents([doc.page_content for doc in dense_docs])\n\n    # MMR Reordering\n    mmr_selected_docs = mmr_rerank(query_embedding, dense_embeddings, dense_docs, lambda_param=lambda_param, k=k)\n    return mmr_selected_docs\n\n# The retrieve function below is used for hybrid approach\n\n# def retrieve(query, k=5):\n#     # Dense retrieval\n#     query_embedding = embedding_model.embed_query(query)\n#     results_embedding = vectordb.similarity_search_with_score_by_vector(query_embedding, k=k)\n\n#     # Sparse retrieval (BM25)\n#     results_bm25 = [(idx, bm25.get_scores(query.split())[idx]) for idx in range(len(texts))]\n#     results_bm25 = sorted(results_bm25, key=lambda x: x[1], reverse=True)[:k]\n#     results_bm25_docs = [(Document(page_content=texts[idx], metadata=metadata[idx]), score)\n#                          for idx, score in results_bm25]\n\n#     # Reciprocal Rank Fusion (no re-trimming inside)\n#     fused_results = reciprocal_rank_fusion(results_bm25_docs, results_embedding)\n\n#     # Lookup dictionary to map back to full Document objects\n#     doc_lookup = {doc.page_content: doc for doc, _ in results_bm25_docs + results_embedding}\n\n#     # Return top-k fused documents\n#     return [doc_lookup[doc_id] for doc_id, _ in fused_results if doc_id in doc_lookup][:k]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T07:09:54.037554Z","iopub.status.idle":"2025-04-15T07:09:54.038420Z","shell.execute_reply.started":"2025-04-15T07:09:54.038118Z","shell.execute_reply":"2025-04-15T07:09:54.038157Z"},"id":"TMLpBaa0nWo4"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eval_data = []\n# List of relevant answers in the same order as the original questions\nrelevant_answers = [\n\n    \"\"\"Under the Zainab Alert, Response and Recovery Act, 2020, “abduction” includes:\n    - Inducing a child under the age of 18 by deceit, force, or threat to move from one place to another, or to do any act.\n    - Taking or detaining a child unlawfully from the lawful custody of a parent or legal guardian.\n    - It includes the act of kidnapping as defined under the Pakistan Penal Code, 1860.\"\"\",\n\n    \"\"\"The Bonded Labour System (Abolition) Act of 1992 abolished all forms of bonded labour in Pakistan. Specifically, Section 6 of the Act states that any existing bonded debts at the time of the Act's commencement are extinguished. This means that bonded labourers are no longer obligated to repay such debts, and any agreements or customs enforcing bonded labour are rendered null and void.\"\"\",\n\n    \"\"\"Under Section 15 of the Bonded Labour System (Abolition) Act, Vigilance Committees are established to ensure the implementation of the Act. These committees are responsible for:\n    - Monitoring the presence of bonded labour in their respective areas.\n    - Rehabilitating freed bonded labourers.\n    - Ensuring that the provisions of the Act are enforced effectively.\n\n    They serve as a bridge between the government and the community to eradicate bonded labour practices.\"\"\",\n\n    \"\"\"In Pakistan, women's inheritance rights are protected under Islamic law, which mandates that female heirs receive their due shares of inheritance. The Supreme Court of Pakistan has emphasized that any attempt to deprive women of their inheritance rights is a violation of Islamic principles and the law. The Court has ruled that properties of deceased individuals vest immediately in their legal heirs upon death, and any denial of this right, especially to female heirs, is unacceptable.\"\"\",\n\n    \"\"\"Pakistan has enacted laws to address domestic violence, with specific legislation varying by province. For instance, the Punjab Protection of Women Against Violence Act 2016 provides mechanisms for protection and redress for victims of domestic abuse. Penalties for perpetrators can include imprisonment, fines, and restraining orders. However, enforcement remains a challenge, and advocacy continues for more robust implementation of these laws to protect women effectively.\"\"\",\n\n    \"\"\"Child marriage laws in Pakistan vary by region:\n    - Sindh: The Sindh Child Marriage Restraint Act 2013 sets the minimum marriage age at 18 for both males and females. Violations can result in imprisonment and fines.\n    - Punjab: The Punjab Marriage Restraint Act 2015 maintains the minimum marriage age at 16 for females and 18 for males. Efforts are ongoing to raise the minimum age for females to 18.\n    - Khyber Pakhtunkhwa and Balochistan: These provinces still follow the Child Marriage Restraint Act of 1929, which sets the minimum marriage age at 16 for females.\n\n    Despite these laws, child marriages persist, particularly in rural areas, due to cultural practices and lack of enforcement.\"\"\",\n\n\n    \"\"\"The medical examination must be conducted by a registered medical practitioner—preferably a female if the victim is female—immediately after the offence.\n    Consent of the victim or their guardian must be obtained. The report should include the victim’s details, injuries, mental condition, materials collected for DNA, and exact timing of the examination.\n    DNA samples must be collected with consent and sent promptly to a forensic lab while ensuring confidentiality.\"\"\"\n\n\n\n]\n\nfor i in range(len(eval_data)):\n    eval_data[i][\"ground_truth\"] = relevant_answers[i]\n","metadata":{"id":"Hj2PdJY98mil"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sentence_transformers import CrossEncoder\n\nreranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n\ndef rerank_documents(question, docs, top_k=5):\n    pairs = [[question, doc.page_content] for doc in docs]\n    scores = reranker.predict(pairs)\n    scored_docs = list(zip(docs, scores))\n    scored_docs.sort(key=lambda x: x[1], reverse=True)\n    return [doc for doc, _ in scored_docs[:top_k]]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nimport requests\nfrom IPython.display import Markdown\nimport re\nimport torch\n\n\n# Constants\nGROQ_API_KEY = \"you_api_key\"\nGROQ_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n\ntotal_retrieval_time = 0\ntotal_generation_time = 0\neval_data = []\n\ndef call_groq(prompt, modelName):\n    headers = {\n        \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    payload = {\n        \"model\": modelName,\n        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n        \"temperature\": 0.6\n    }\n\n    while True:\n        response = requests.post(GROQ_URL, headers=headers, json=payload)\n\n        if response.status_code == 429:\n            retry_after = response.headers.get(\"Retry-After\")\n            wait = int(retry_after) if retry_after else 60\n            print(f\"🚫 Rate limit hit. Retrying in {wait} seconds...\")\n            time.sleep(wait + 1)\n            continue\n\n        response.raise_for_status()\n        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n\ndef ask_question(question, k, generation_model, judge_model, chunk_size, chunk_overlap):\n    global total_retrieval_time, total_generation_time\n\n    start_retrieval = time.time()\n    docs = retrieve(question, k=k)\n    retrieval_duration = time.time() - start_retrieval\n    docs = rerank_documents(question, docs, top_k=k)\n    total_retrieval_time += retrieval_duration\n\n    combined_context = \"\"\n    for i, doc in enumerate(docs):\n        page = doc.metadata.get(\"page\", \"?\")\n        combined_context += f\"\\nDocument {i+1} (Page {page}):\\n{doc.page_content}\\n\"\n\n    print(\"\\n🔍 Top Retrieved Documents:\\n\")\n    for i, doc in enumerate(docs):\n        page = doc.metadata.get(\"page\", \"?\")\n        print(f\"Document {i+1} (Page {page}): {doc.page_content[:500]}...\\n{'-'*50}\")\n\n    start_generation = time.time()\n    prompt = f\"\"\"Answer the following question based on the legal and social context provided below, which may include topics such as women's rights, juvenile justice, child protection, bonded labor, and labor laws in Pakistan.\n\n{combined_context}\n\nQuestion: {question}\n\nInstructions:\n    - Ensure your answer is grounded in the context\n    - Use clear, factual language\n    - Format using bullet points or headings if needed\"\"\"\n    response = call_groq(prompt, generation_model)\n    generation_duration = time.time() - start_generation\n    total_generation_time += generation_duration\n\n    # Clear GPU memory if needed\n    torch.cuda.empty_cache()\n\n    print(\"\\n==============================\")\n    print(\"🧠 Question:\")\n    print(question)\n    print(\"\\n💬 Generated Answer:\")\n    print(response)\n    print(\"==============================\")\n    print(f\"\\n⏱ Retrieval Time: {retrieval_duration:.2f}s | Generation Time: {generation_duration:.2f}s\")\n\n    # LLM Judge Evaluation\n    judge_prompt = f\"\"\"\nYou are a strict evaluator. Given the context and the generated answer, assess the following:\n1. *Faithfulness*: Is the answer factually accurate based on the context provided?\n2. *Relevance*: Does the answer directly address the question using only the context?\n\nRespond with:\n- Faithfulness Score (0-5):\n- Relevance Score (0-5):\n- Justification:\n\n### Context:\n{combined_context}\n\n### Question:\n{question}\n\n### Answer:\n{response}\n    \"\"\"\n    judgment = call_groq(judge_prompt, judge_model)\n    print(\"\\n📊 LLM Evaluation:\\n\", judgment)\n\n    faithfulness_score = None\n    relevance_score = None\n    \n    faithfulness_match = re.search(\n        r\"Faithfulness(?: Score)?[^0-9]*([\\d.]+)\\s*/?\\s*5\", judgment, re.IGNORECASE\n    )\n    relevance_match = re.search(\n        r\"Relevance(?: Score)?[^0-9]*([\\d.]+)\\s*/?\\s*5\", judgment, re.IGNORECASE\n    )\n    \n    if faithfulness_match:\n        faithfulness_score = float(faithfulness_match.group(1))  # Allow decimal scores\n    if relevance_match:\n        relevance_score = float(relevance_match.group(1))  # Allow decimal scores\n    \n    if faithfulness_score is None or relevance_score is None:\n        print(\"⚠️ Could not parse evaluation scores!\")\n\n\n    eval_data.append({\n        \"chunk_size\": chunk_size,\n        \"chunk_overlap\": chunk_overlap,\n        \"question\": question,\n        \"answer\": response,\n        \"contexts\": [doc.page_content for doc in docs],\n        \"retrieval_time\": retrieval_duration,\n        \"generation_time\": generation_duration,\n        \"total_time\": retrieval_duration + generation_duration,\n        \"k\": k,\n        \"generation_model\": generation_model,\n        \"judge_model\": judge_model,\n        \"llm_judgment\": judgment,\n        \"faithfulness_score\": faithfulness_score,\n        \"relevance_score\": relevance_score\n    })\n","metadata":{"id":"PIVgY1KwB6rN"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The cell below was used when using Hugging Face models instead of Groq Inference API","metadata":{}},{"cell_type":"code","source":"# import time\n# import torch\n\n# total_retrieval_time = 0\n# total_generation_time = 0\n# eval_data = []\n\n# # Limit the maximum length of the combined context\n# max_context_length = 2000  # Define a maximum context length to reduce GPU load\n\n# def ask_question(question):\n#     global total_retrieval_time, total_generation_time\n\n#     # Record the start time for retrieval\n#     start_retrieval = time.time()\n#     docs = retrieve(question)\n#     end_retrieval = time.time()\n#     retrieval_duration = end_retrieval - start_retrieval\n#     total_retrieval_time += retrieval_duration\n\n#     # Combine all documents into one context, with truncation\n#     combined_context = \"\"\n#     for i, doc in enumerate(docs[:3]):\n#         page_num = doc.metadata.get('page', '?')\n#         content = doc.page_content[:500]  # Truncate each document to 500 characters\n#         combined_context += f\"\\nDocument {i+1} (Page {page_num}):\\n{content}\\n\"\n#         if len(combined_context) > max_context_length:\n#             break  # Stop appending if we've reached the maximum context length\n\n#     print(\"\\n🔍 Top Retrieved Documents:\\n\")\n#     for i, doc in enumerate(docs[:3]):  # Limit to 3 documents for display\n#         page_num = doc.metadata.get('page', '?')\n#         print(f\"Document {i+1} (Page {page_num}): {doc.page_content[:500]}...\\n{'-'*50}\")\n\n#     # Generate answer\n#     start_generation = time.time()\n#     prompt = f\"\"\"Answer the following question based on the legal and social context provided below, which may include topics such as women's rights, juvenile justice, child protection, bonded labor, and labor laws in Pakistan.\n\n#     {combined_context}\n\n#     Question: {question}\n\n#     Instructions:\n#     - Ensure your answer is grounded in the context\n#     - Use clear, factual language\n#     - Format using bullet points or headings if needed\"\"\"\n#     response = generator(\n#         [{\"role\": \"user\", \"content\": prompt}],\n#         max_new_tokens=250  # Adjust this to desired word/token limit\n#     )[0][\"generated_text\"]\n\n#     end_generation = time.time()\n#     generation_duration = end_generation - start_generation\n#     total_generation_time += generation_duration\n\n#     # Clear GPU memory after generation\n#     torch.cuda.empty_cache()\n\n#     # Display the result\n#     display(Markdown(f\"**Question:** {question}\"))\n#     display(Markdown(f\"**Answer:** {response}\"))\n\n#     print(f\"\\n⏱️ Retrieval Time: {retrieval_duration:.2f}s | Generation Time: {generation_duration:.2f}s\")\n\n#     # LLM Judge Evaluation\n#     judge_prompt = f\"\"\"\n# You are a strict evaluator. Given the context and the generated answer, assess the following:\n# 1. **Faithfulness**: Is the answer factually accurate based on the context provided?\n# 2. **Relevance**: Does the answer directly address the question using only the context?\n\n# Respond with:\n# - Faithfulness Score (0-5):\n# - Relevance Score (0-5):\n# - Justification:\n\n# ### Context:\n# {combined_context}\n\n# ### Question:\n# {question}\n\n# ### Answer:\n# {response}\n# \"\"\"\n\n#     with torch.inference_mode():\n#       judgment = generator([{\"role\": \"user\", \"content\": judge_prompt}])[0][\"generated_text\"]\n\n#     print(\"\\n📊 LLM Evaluation:\\n\", judgment)\n\n#     # Save evaluation data\n#     eval_data.append({\n#         \"question\": question,\n#         \"answer\": response,\n#         \"relevant_answer\": combined_context,\n#         \"contexts\": [doc.page_content for doc in docs],\n#         \"llm_judgment\": judgment\n#     })\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T07:09:54.045583Z","iopub.status.idle":"2025-04-15T07:09:54.046647Z","shell.execute_reply.started":"2025-04-15T07:09:54.046318Z","shell.execute_reply":"2025-04-15T07:09:54.046342Z"},"id":"qajlGASunWo5"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"questions = [\n    \"What does abduction mean under the law of Pakistan?\",\n    \"How does the Bonded Labour System Act protect laborers from debt bondage?\",\n    \"What role do Vigilance Committees play according to the Act?\",\n    \"What initiatives are there to protect women's entitlement to inheritance?\",\n    \"What legal measures and punishments exist in Pakistan to address domestic violence against women?\",\n    \"What are the current legal provisions and age restrictions regarding child marriage in Pakistan?\",\n    \"What are the requirements for medical examination and DNA testing of a rape or sexual abuse victim?\",\n]\n\n# Define your models\ngeneration_model = \"meta-llama/llama-4-maverick-17b-128e-instruct\"\njudge_model = \"deepseek-r1-distill-llama-70b\"\n\n# Parameter sets\nchunk_sizes = [256, 512, 1024, 2048]\nchunk_overlaps = [32, 64, 128, 128]\nk_values = [4, 6, 8]\n\nfor chunk_size, chunk_overlap in zip(chunk_sizes, chunk_overlaps):\n    print(f\"\\n🚀 Processing with chunk size: {chunk_size}, overlap: {chunk_overlap}\")\n    \n    # Chunk and split the documents\n    chunk_and_split(all_docs, chunk_size, chunk_overlap)\n\n    for k in k_values:\n        print(f\"\\n🔍 Evaluating with top-{k} retrieved documents...\")\n\n        for q in questions:\n            ask_question(\n                question=q,\n                k=k,\n                generation_model=generation_model,\n                judge_model=judge_model,\n                chunk_size=chunk_size,\n                chunk_overlap=chunk_overlap\n            )\n            display(Markdown(f\"**k = {k} | chunk size = {chunk_size}, overlap = {chunk_overlap}**\"))\n            display(Markdown(\"---\"))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T07:09:54.048073Z","iopub.status.idle":"2025-04-15T07:09:54.048998Z","shell.execute_reply.started":"2025-04-15T07:09:54.048791Z","shell.execute_reply":"2025-04-15T07:09:54.048808Z"},"id":"0c4smpMenWo5"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\n# Make sure eval_data exists and is not empty\nif \"eval_data\" in globals() and eval_data:\n    df = pd.DataFrame(eval_data)\n\n    # Convert columns to numeric if needed\n    df[\"faithfulness_score\"] = pd.to_numeric(df[\"faithfulness_score\"], errors=\"coerce\")\n    df[\"relevance_score\"] = pd.to_numeric(df[\"relevance_score\"], errors=\"coerce\")\n\n    # Group by chunk_size, overlap, and k\n    grouped = df.groupby([\"chunk_size\", \"chunk_overlap\", \"k\"])[\n        [\"retrieval_time\", \"generation_time\", \"faithfulness_score\", \"relevance_score\"]\n    ].mean().reset_index()\n\n    print(\"\\n📊 Summary grouped by chunk size, overlap, and k:\")\n    print(grouped)\n\n    # Create output directory\n    os.makedirs(\"rag_eval_charts\", exist_ok=True)\n\n    # ------------------- Lineplot: Faithfulness & Relevance vs Chunk Size -------------------\n    plt.figure(figsize=(14, 6))\n\n    # Faithfulness\n    plt.subplot(1, 2, 1)\n    sns.lineplot(data=grouped, x=\"chunk_size\", y=\"faithfulness_score\", hue=\"k\", marker=\"o\")\n    plt.title(\"Faithfulness vs Chunk Size\")\n    plt.xlabel(\"Chunk Size\")\n    plt.ylabel(\"Faithfulness Score\")\n    plt.grid(True)\n\n    # Relevance\n    plt.subplot(1, 2, 2)\n    sns.lineplot(data=grouped, x=\"chunk_size\", y=\"relevance_score\", hue=\"k\", marker=\"o\")\n    plt.title(\"Relevance vs Chunk Size\")\n    plt.xlabel(\"Chunk Size\")\n    plt.ylabel(\"Relevance Score\")\n    plt.grid(True)\n\n    plt.tight_layout()\n    plt.savefig(\"rag_eval_charts/lineplot_faithfulness_relevance_vs_chunk_size.png\")\n    plt.show()\n\n    # ------------------- Heatmaps: Chunk Size × k -------------------\n    for metric in [\"faithfulness_score\", \"relevance_score\"]:\n        pivot = grouped.pivot_table(index=\"chunk_size\", columns=\"k\", values=metric)\n        plt.figure(figsize=(8, 6))\n        sns.heatmap(pivot, annot=True, fmt=\".2f\", cmap=\"YlGnBu\")\n        title = f\"{metric.replace('_', ' ').title()} Heatmap (Chunk Size × k)\"\n        plt.title(title)\n        plt.ylabel(\"Chunk Size\")\n        plt.xlabel(\"k\")\n\n        filename = f\"rag_eval_charts/heatmap_{metric}.png\"\n        plt.savefig(filename)\n        plt.show()\n\nelse:\n    print(\"⚠️ `eval_data` is empty or not defined.\")\n","metadata":{"id":"ex33bcDXbt5Q"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def print_total_times(num_queries):\n#     # Display total times after all questions\n#     print(f\"\\n🔢 Total Retrieval Time: {total_retrieval_time:.2f} seconds\")\n#     print(f\"🔢 Total Generation Time: {total_generation_time:.2f} seconds\")\n#     print(f\"🔢 Total Time (Retrieval + Generation): {total_retrieval_time + total_generation_time:.2f} seconds\")\n\n#     # Display average times per query\n#     if num_queries > 0:\n#         avg_retrieval_time = total_retrieval_time / num_queries\n#         avg_generation_time = total_generation_time / num_queries\n#         avg_total_time = (total_retrieval_time + total_generation_time) / num_queries\n\n#         print(f\"\\n📊 Average Retrieval Time: {avg_retrieval_time:.2f} seconds/query\")\n#         print(f\"📊 Average Generation Time: {avg_generation_time:.2f} seconds/query\")\n#         print(f\"📊 Average Total Time: {avg_total_time:.2f} seconds/query\")\n#     else:\n#         print(\"\\n⚠️ No queries processed.\")\n\n# print_total_times(len(eval_data))\n","metadata":{"id":"dixPb4LhvXiJ","outputId":"7ec7d670-c1e0-446a-f497-2090f8380b5b"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import re\n\n# faithfulness_scores = []\n# relevance_scores = []\n\n# for i, entry in enumerate(eval_data):\n#     judgment = entry.get(\"llm_judgment\", \"\")\n\n#     # Flexible regex to extract scores\n#     faithfulness_match = re.search(r\"Faithfulness.*?(\\d+)\", judgment, re.IGNORECASE)\n#     relevance_match = re.search(r\"Relevance.*?(\\d+)\", judgment, re.IGNORECASE)\n\n#     if faithfulness_match and relevance_match:\n#         faithfulness_scores.append(int(faithfulness_match.group(1)))\n#         relevance_scores.append(int(relevance_match.group(1)))\n#     else:\n#         print(f\"⚠️ Judgment {i+1} did not contain extractable scores:\\n{judgment}\\n{'-'*60}\")\n\n# # Print average if we have any valid scores\n# if faithfulness_scores and relevance_scores:\n#     avg_faithfulness = sum(faithfulness_scores) / len(faithfulness_scores)\n#     avg_relevance = sum(relevance_scores) / len(relevance_scores)\n\n#     print(\"\\n📈 **Combined Evaluation Summary**\")\n#     print(f\"- Average Faithfulness Score: {avg_faithfulness:.2f}/5\")\n#     print(f\"- Average Relevance Score: {avg_relevance:.2f}/5\")\n# else:\n#     print(\"❌ No valid scores found. Check the format of LLM judgments.\")\n","metadata":{"id":"HhZNjSsKdzn2","outputId":"7857e310-74e9-4cc9-9b05-30e29d0ecf78"},"outputs":[],"execution_count":null}]}